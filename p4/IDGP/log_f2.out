nohup: 忽略输入
../FEI-dataset/f2/f2
   	      	                    fitness                    	                   size_tree                   
   	      	-----------------------------------------------	-----------------------------------------------
gen	nevals	avg   	gen	max  	min  	nevals	std    	avg 	gen	max	min	nevals	std    
0  	100   	66.779	0  	91.33	39.33	100   	17.8407	7.51	0  	46 	2  	100   	7.43034
1  	100   	84.4585	1  	92   	42.67	100   	9.31443	10.3	1  	46 	2  	100   	11.2067
2  	100   	88.9122	2  	94   	36   	100   	5.67934	21.33	2  	59 	2  	100   	14.1993
3  	100   	90.66  	3  	94   	75.33	100   	2.99554	28.77	3  	47 	7  	100   	8.04842
4  	100   	91.927 	4  	94   	85.33	100   	1.60859	30.81	4  	55 	7  	100   	10.2691
5  	100   	92.134 	5  	94   	86   	100   	1.49707	29.69	5  	48 	10 	100   	11.0469
6  	100   	91.7663	6  	94   	71.33	100   	2.88051	26.57	6  	52 	2  	100   	11.9141
7  	100   	92.0796	7  	94   	41.33	100   	5.5333 	24.58	7  	51 	5  	100   	11.2651
/usr/pkg/lib/python3.9/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn("Liblinear failed to converge, increase "
/usr/pkg/lib/python3.9/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn("Liblinear failed to converge, increase "
8  	100   	91.9463	8  	94.67	40.67	100   	6.44172	20.5 	8  	51 	2  	100   	9.55667
9  	100   	92.6932	9  	94.67	41.33	100   	5.53413	20.1 	9  	51 	2  	100   	9.0978 
10 	100   	93.4537	10 	94.67	87.33	100   	1.48974	21.49	10 	51 	5  	100   	8.12588
11 	100   	93.5474	11 	94.67	86   	100   	1.75903	23.23	11 	48 	8  	100   	7.18033
12 	100   	93.8747	12 	94.67	90   	100   	1.10721	26.72	12 	68 	8  	100   	8.3858 
13 	100   	93.2684	13 	94.67	41.33	100   	5.83691	26.51	13 	41 	2  	100   	7.56372
14 	100   	93.8418	14 	94.67	62   	100   	3.39485	27.75	14 	47 	2  	100   	7.38698
15 	100   	93.6217	15 	94.67	62   	100   	3.87558	27.49	15 	42 	2  	100   	5.96405
16 	100   	94.0011	16 	94.67	88   	100   	1.03435	27.31	16 	41 	8  	100   	5.70385
17 	100   	94.0754	17 	94.67	84   	100   	1.65293	27.53	17 	41 	2  	100   	6.14403
18 	100   	94.2822	18 	94.67	91.33	100   	0.688811	27.47	18 	41 	17 	100   	4.5617 
19 	100   	94.0416	19 	94.67	86   	100   	1.13173 	27.44	19 	41 	7  	100   	6.03211
20 	100   	94.2625	20 	94.67	87.33	100   	0.9574  	27.59	20 	42 	12 	100   	5.41497
21 	100   	93.9487	21 	94.67	71.33	100   	2.46621 	27.22	21 	45 	2  	100   	7.26303
22 	100   	94.1019	22 	94.67	87.33	100   	1.22841 	27.21	22 	45 	2  	100   	7.47167
23 	100   	94.1826	23 	94.67	84   	100   	1.65503 	27.17	23 	54 	2  	100   	8.67416
24 	100   	94.1287	24 	94.67	77.33	100   	1.94875 	28.68	24 	53 	6  	100   	8.24   
25 	100   	94.109 	25 	94.67	71.33	100   	2.39486 	29.23	25 	53 	2  	100   	8.32809
26 	100   	94.1688	26 	94.67	86   	100   	1.15718 	29.98	26 	58 	8  	100   	8.8521 
27 	100   	94.3824	27 	94.67	90   	100   	0.662891	28.92	27 	58 	17 	100   	9.76492
28 	100   	94.3292	28 	94.67	89.33	100   	0.941413	28.88	28 	71 	8  	100   	11.5942
29 	100   	94.4426	29 	94.67	92   	100   	0.576487	30.11	29 	59 	17 	100   	10.811 
30 	100   	94.2359	30 	94.67	86   	100   	1.27731 	29.37	30 	58 	8  	100   	10.8845
31 	100   	94.2227	31 	94.67	82   	100   	1.6314  	31.01	31 	58 	8  	100   	12.4888
32 	100   	94.4627	32 	94.67	87.33	100   	0.821467	31.75	32 	58 	12 	100   	12.6074
33 	100   	94.3696	33 	94.67	86   	100   	1.1529  	32.83	33 	87 	5  	100   	13.3019
34 	100   	94.4426	34 	94.67	88   	100   	0.785553	33.54	34 	87 	5  	100   	15.6406
35 	100   	94.4493	35 	94.67	88.67	100   	0.713026	33.63	35 	87 	17 	100   	14.5758
36 	100   	94.4427	36 	94.67	87.33	100   	0.824206	35.59	36 	88 	13 	100   	16.171 
37 	100   	93.9426	37 	94.67	61.33	100   	3.57636 	37.61	37 	88 	5  	100   	17.7876
38 	100   	94.2895	38 	94.67	86   	100   	1.30126 	38.97	38 	100	8  	100   	18.2874
39 	100   	93.776 	39 	94.67	44   	100   	5.53612 	37.23	39 	100	2  	100   	19.28  
40 	100   	94.4695	40 	94.67	92.67	100   	0.495066	38   	40 	100	14 	100   	18.3079
41 	100   	94.1492	41 	94.67	84   	100   	1.79621 	37.2 	41 	100	5  	100   	18.4451
42 	100   	94.136 	42 	94.67	82.67	100   	1.86969 	40.95	42 	100	10 	100   	18.3665
43 	100   	94.5161	43 	94.67	92   	100   	0.42117 	40.83	43 	100	12 	100   	16.1685
44 	100   	94.4762	44 	95.33	86   	100   	0.940023	44.33	44 	71 	8  	100   	15.8588
45 	100   	94.4557	45 	95.33	88   	100   	0.799939	43.1 	45 	67 	5  	100   	15.6994
/usr/pkg/lib/python3.9/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn("Liblinear failed to converge, increase "
/usr/pkg/lib/python3.9/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn("Liblinear failed to converge, increase "
46 	100   	94.5016	46 	95.33	86.67	100   	0.920777	43.01	46 	75 	8  	100   	15.4671
47 	100   	94.3604	47 	95.33	87.33	100   	1.07661 	38.57	47 	67 	5  	100   	12.8415
48 	100   	92.8536	48 	95.33	38.67	100   	7.11342 	35.57	48 	67 	2  	100   	13.7239
49 	100   	94.2131	49 	95.33	84   	100   	1.46888 	37.56	49 	73 	7  	100   	11.7382
50 	100   	93.1793	50 	95.33	46   	100   	6.74862 	33.98	50 	73 	5  	100   	8.95096
Best individual  FeaCon2(FeaCon2(FeaCon3(Global_SIFT(Image0), Local_SIFT(Region_S(Image0, 111, 67, 45)), Global_DIF(Image0)), Global_HOG(Image0)), FeaCon2(FeaCon3(Global_SIFT(Image0), Local_SIFT(Region_S(Image0, 111, 67, 40)), Local_uLBP(Region_R(Image0, 43, 17, 38, 50))), Global_HOG(Image0)))
Test results   98.0
Train time   51919.920285144995
Test time   39.02699226500408
End
